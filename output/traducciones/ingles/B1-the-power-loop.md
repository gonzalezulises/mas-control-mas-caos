# The Power Loop

> "Power tends to corrupt, and absolute power corrupts absolutely."
>
> — Lord Acton, *Letter to Mandell Creighton* (1887)

<!-- block: recognition -->
How many times have you approved something knowing the numbers were optimistic? Not fraudulent, not fabricated—optimistic. The assumptions that closed the business case were the ones the sponsor needed to be true, not the ones the available evidence supported. You knew it. Several people in the room knew it. Nobody said it aloud because saying it would have stopped something that already had momentum, and stopping something with momentum has a political cost that nobody wanted to pay at that moment.

That decision not to say anything—to approve with unexpressed reservations, to vote yes while thinking "hopefully it works"—was not cowardice or negligence. It was rational calculation within a system where the cost of objecting is immediate and personal, while the cost of approving something problematic is deferred and collective. The system trained you to do exactly what you did. And it will keep doing so until something changes the incentive structure.

The reports keep being positive, but they no longer reflect the terrain with precision. The metrics being measured are those that confirm progress, not those that would reveal emerging problems. Follow-up meetings become validation ceremonies where the implicit objective is to maintain the climate of confidence. Risks are mentioned at the end of the agenda, with soft language and qualifiers that minimize their urgency. Nobody wants to be the one who ruins the tone of the room. Nobody wants to seem like the obstacle.

Information flows upward filtered by each layer—what research in organizational behavior calls upward distortion. What reaches the committee is an edited version of operational reality. Not out of malice, but by structure. Each manager adjusts the message for their audience. Each director contextualizes the data to avoid alarming unnecessarily. Each VP presents the panorama their sponsor wants to see. The result is a coherent image that does not correspond to the territory.

Boeing lived it with the 737 MAX. It was not a one-off error by a distracted engineer or a corrupt manager. It was not an act of criminal negligence or a conspiracy to deceive the regulator. It was a sequence that any executive would recognize if they looked at it without the filter of distance: real and legitimate competitive pressure against Airbus, a strategic decision to accelerate that seemed reasonable at the time given the market context, engineering teams forced to meet deadlines they had not defined and over which they had no control, internal warning signals that were ignored or minimized because they contradicted organizational momentum, and an entire organization—from the production line to the board—convinced that internal controls were sufficient to capture any problem before it became serious.

Boeing's scale is larger. The dynamic is not.

Nobody at Boeing thought they were taking a catastrophic risk. Everyone thought they were doing their job the best way possible given the circumstances. The system was working according to its own metrics. The planes were coming off the production line. Deliveries were being met within acceptable ranges. The quarterly numbers were closing. The stock was rising.

When the problem became visible to the world, it was already too late to correct without massive cost. Not because technical talent was lacking or because individual malice abounded, but because the very structure of the organization had turned acceleration into virtue and pause into defect. The system had consistently rewarded those who pushed forward and had penalized—subtly but effectively—those who asked to stop and verify.

Boeing in Seattle and OGX in Rio de Janeiro operated under the same physics, separated by an ocean and a completely different industry.

OGX was the largest private oil company in Brazil, founded in 2007 by Eike Batista, then the richest man in the country. The promise was to transform Brazil into a global hub for private oil exploration. The 2008 IPO raised 6.7 billion reais, the largest in the history of the Brazilian stock exchange up to that point. By 2010, each share reached 23 reais, and by 2012 Batista's personal fortune reached 35 billion dollars, placing him as the seventh richest man in the world.

The power loop worked exactly as this chapter describes. The first wells drilled reported promising findings. Each discovery announcement generated more market confidence, more available capital, more pressure to expand and accelerate. OGX promised to produce 750,000 barrels daily. Analysts validated the projections. Investors multiplied their bets. The press celebrated the new Latin American energy giant. Organizational momentum became its own justification.

In 2012, internal reports began to reveal that several explored fields were not economically viable. But the system was already too politically committed to its own success narrative. In 2013, OGX admitted that its actual production would be dramatically lower than promised: not 750,000 barrels daily, but barely 15,000. The company declared the largest bankruptcy in Brazilian corporate history (Reuters, 2013), with liabilities of approximately 13 billion reais. Market capitalization fell more than 45 billion dollars from its peak.

Batista went from being the seventh richest man in the world to having a negative net worth of one billion dollars. In 2018 he was sentenced to 30 years in prison for bribery. But the collapse was not a product of the subsequent corruption; the corruption was a symptom of the same system that generated the collapse. Organizational amplification worked exactly as designed: it turned promises into commitment, commitment into pressure, pressure into blindness.

WeWork demonstrates that the pattern does not require decades to manifest. In less than ten years, the company went from a shared-space startup to a private valuation of 47 billion dollars in 2019. Each funding round fed the loop: more available capital, more aggressive expansion, growth metrics that justified the next round. Founder Adam Neumann operated with the conviction that expansion speed validated the model. Investors, including SoftBank with 10 billion dollars committed, had too much politically invested to question the fundamentals. When WeWork attempted to go public, public scrutiny revealed what the internal loop had obscured: losses of 1.9 billion dollars on revenues of 1.8 billion, dysfunctional corporate governance, and a business model whose viability nobody within the system had seriously verified. The valuation collapsed from 47 billion to less than 10 billion in weeks. But the loop had worked perfectly for years: every internal metric indicated success while exposure accumulated.

This sequence is not exclusive to Boeing, OGX, or WeWork. It is not a problem of the aeronautical industry, nor the oil industry, nor tech. It is the dynamic signature of any organization with enough power to amplify its own decisions. You have seen it in your industry. You have probably lived it from the inside, perhaps without having a name to describe it, perhaps attributing it to local factors when in reality it was a structural pattern.

<!-- block: relief -->
This did not happen because someone was incompetent. It happened because the system worked exactly as it was designed to work: amplifying its own energy until it found an external limit—in this case, catastrophic.

There is a comfortable narrative that appears after each visible corporate failure: the villain narrative. Someone made a bad decision out of greed or stupidity. Someone was negligent in their basic responsibilities. Someone prioritized the quarterly bonus over long-term safety. Someone knew and did not act. This narrative is useful for regulators who need individual responsible parties, convenient for the press that needs stories with clear antagonists, and comforting for those observing from outside who want to believe it would not happen to them because they are competent and ethical.

But the villain narrative is false. It is a simplification that obscures the real dynamic and, worse, prevents learning anything useful from the failure.

Organizations do not fail due to lack of talent. The people at Boeing were world-class engineers, graduates of the most prestigious technical universities, with decades of experience designing and building the safest aircraft in history. The managers had impeccable track records navigating complex projects under pressure. The executives had led the company through previous crises with demonstrated success. There was no deficit of technical capability or managerial experience or professional commitment.

Organizations fail because their structure systematically and consistently rewards acceleration and penalizes pause. Each layer of management adds forward pressure, not out of malice but by design. A project manager who reports delays faces uncomfortable questions, additional reviews, questioning of their capability; one who reports progress on schedule receives tacit approval and is left alone to continue executing. A director who asks for more resources must justify themselves extensively, defend assumptions, submit to scrutiny; one who delivers results with fewer resources than planned is celebrated as efficient and promoted as an example. A VP who publicly questions the viability of an initiative sponsored by the CEO puts their career at risk, their relationships, their future in the organization; one who aligns and executes without questioning accumulates political capital they can use in future battles.

These pressures are not conspiracies. They do not require secret agreements or malicious intentions. They are structural incentives that operate invisibly but effectively. They are embedded in how executive reports are designed, how meeting agendas are structured, how performance evaluation criteria are defined, how bonuses and recognition are distributed, how promotion and assignment decisions are made. Nobody needs to give an explicit order to "ignore the warning signs and keep going no matter what." The system produces that result without written instructions, without compromising memos, without evidence of wrongful intent.

Each successful quarterly report generates expectation of more success in the next. Each decision to continue makes it politically more costly to stop afterward. Each month that passes without visible problems reinforces the collective belief that the chosen path is correct and that additional precautions would be unnecessary.

It was not individual negligence. It was organizational physics: the laws of motion that govern how energy flows, amplifies, and finds limits within systems with concentrated power. And it is the same physics operating in your organization right now, at this moment, in initiatives you probably consider successful precisely because they have not yet found their limit.

<!-- block: cause -->
Organizational power is a self-amplifying loop. Linear progress does not exist.

The loop has a structure that can be precisely described:

![The power loop](assets/generated/diagrams/B1-loop-poder.png)

This sequence is not metaphor. It is a literal description of how organizations with real capacity for action in the world function.

The loop is amoral. It does not distinguish between valuable and destructive initiatives. It amplifies what it receives without evaluating whether it deserves amplification. A project that genuinely creates value and a project that accumulates catastrophic exposure feel identical from inside the loop while they operate. Both generate visible results, political commitment, demand for more resources. The difference only becomes visible when the loop finds an external limit: in the first case, that limit is success; in the second, collapse.

The fundamental dynamic: initial energy generates visible results. It can be financial, political, or operational energy. The specific type matters less than its universal effect: it produces organizational movement. And movement generates results that, in the short term, are indistinguishable between real and apparent for those observing from above.

The results generate political commitment from those involved. The sponsor has their reputation linked to the final outcome. The team has invested effort and wants to see return. The stakeholders who supported approval need it to work to validate their judgment. Nobody wants to be associated with a visible failure.

The accumulated commitment demands more energy to sustain itself. More resources are justified, scope is expanded, timelines are accelerated, features are added. Each addition seems marginal when presented individually. The sum is exponential. The cycle accelerates again. And again.

At Boeing, the competitive pressure to respond quickly to Airbus generated the strategic decision to modify an existing aircraft—the venerable 737—instead of designing a completely new one from scratch. This decision had impeccable logic at the time it was made: it dramatically reduced development costs because it leveraged existing design, significantly accelerated time to market because it avoided starting from zero, took advantage of regulatory certifications already obtained, minimized pilot retraining costs because they maintained familiarity with the platform. The decision saved time and money in the short term in visible and measurable ways. The savings were internally celebrated as a strategic victory. The celebration generated more pressure to deliver quickly to capitalize on the advantage. Speed became a signal of organizational success and executive capability. Questioning speed implicitly became a signal of disloyalty or lack of commitment to objectives.

Nobody in the decision chain saw the loop while they were inside it operating. Everyone saw individual decisions that seemed correct and reasonable in their immediate context, evaluated with the information available at the time.

The loop does not distinguish between productive momentum heading toward genuine results and destructive momentum heading toward disaster. It has no internal mechanism to differentiate legitimate acceleration toward success from blind acceleration toward the precipice. It only amplifies what it receives, in any direction.

This is the uncomfortable assertion that supports everything that follows in this book: your organization does not progress linearly toward defined objectives. It self-amplifies in the direction it is already moving, whatever that direction may be. If that direction turns out to be correct, the loop produces extraordinary results that retrospectively justify all decisions made. If that direction has hidden defects not visible until it is too late, the loop produces extraordinary catastrophes that seem inexplicable in retrospect. And from inside the loop, while it is operating, both scenarios feel exactly the same: like progress.

When an initiative accelerates without visible brakes, it does not demonstrate viability: it accumulates exposure.

<!-- block: risk -->
The fundamental problem with power loops is that chaos appears late, long after the decisions that caused it were made and celebrated. Early warning signals invariably exist, but the system absorbs them, reinterprets them benignly, or actively silences them.

In any initiative that eventually fails visibly, there is a moment—usually quite early in the process—where someone within the organization saw the problem or at least felt that something was not right. An engineer noticed a technical anomaly that did not fit the specifications and reported it to their manager. A project manager felt from their experience that the committed timelines were unrealistic given known complexities. A financial analyst questioned the return projections because the assumptions seemed optimistic. An area director had an intuition based on previous patterns that something fundamental did not fit the official narrative.

These signals exist. They are neither invisible nor inaccessible. They are there for whoever wants to see them. But in a dynamic of organizational amplification, internal warnings that contradict momentum sound like unjustified obstacles to progress. Technicians who alert about risks seem like professional pessimists or uncommitted to the team's and company's objectives. Managers who ask for a pause to verify seem slow, conservative, or unable to handle the pressure that is normal in competitive environments. Analysts who question optimistic projections seem misaligned with the strategic vision defined by leadership. Directors who express doubts based on intuition seem not to understand the market or to be outdated regarding new realities.

The system does not silence these critical voices with explicit and documented censorship. That would be too crude and would leave uncomfortable evidence. It silences them with subtle but real costs. Whoever consistently alerts about risks pays a price in accumulated political capital, in career and promotion opportunities, in quality of relationships with peers and superiors, in invitations to meetings where real decisions are made. Whoever aligns with the official narrative and executes without questioning is rewarded with visibility, with access, with resources, with the benefit of the doubt when something goes wrong.

No organized conspiracy is needed to produce institutional silence. Just a consistent gradient of incentives that systematically rewards optimism and systematically penalizes caution.

Boeing had experienced engineers who formally alerted about potential problems with the MCAS system and its interaction with pilots. It had veteran test pilots who reported unexpected aircraft behaviors in simulations. It had program managers who expressed documented concern about certification timelines and the pressure to meet them. These voices existed within the organization. They spoke. They wrote memos. They raised flags. The organizational system turned them into background noise that did not alter the trajectory.

The neutralization mechanism is subtle but tremendously effective. An alert that contradicts organizational momentum is not explicitly ignored—that would be too visible and would leave clear responsibility—. It is recontextualized in ways that neutralize it. "It's a minor risk that is being monitored." "It's under control by the corresponding technical team." "We're already managing it within normal processes." "It's not substantially different from other similar projects that turned out well." Each individual recontextualization is locally reasonable and defensible. The cumulative sum of all recontextualizations is institutionalized systemic blindness.

By the time the problem is so large that it is undeniable to everyone, the available options have dramatically reduced. The political and financial cost of stopping exceeds the cost of continuing and hoping it resolves itself—until it stops being so, abruptly, when the cost of continuing reveals itself as infinite.

Boeing discovered this truth when two passenger planes crashed. But the loop had been operating within the organization for years before those events. The warning signals were there from the beginning of the program. The system had metabolized them, integrated them into the official narrative, neutralized them as normal noise of any complex project. It had turned them into an accepted part of the normal landscape of a large organization in motion. The 238-page report by the U.S. House Transportation Committee documented a pattern that matches the dynamic described in this chapter: production pressures that compromised safety, a culture of concealment, and internal warning signals that were ignored or minimized.

Your organization has active loops at this very moment. Some of them produce genuine and sustainable value: teams accelerating toward real and measurable results, initiatives building capabilities that will endure beyond the project, investments generating return that can be verified. Other active loops are accumulating invisible risk: projects advancing on schedule without validating fundamental assumptions, initiatives growing in scope faster than their real execution capacity, strategies depending on market conditions that have already changed without anyone having updated the analysis.

From inside the loop, both types feel exactly the same: like legitimate progress. The executive reports are structurally similar. Follow-up meetings have the same optimistic tone. The selected metrics are moving in the right direction. The fundamental difference between productive loops and destructive loops only becomes visible when it is too late to correct without massive—or catastrophic—cost.

This is the risk that never appears on executive dashboards or in board reports: the structural inability to distinguish, from inside the system while it operates, between productive acceleration that builds value and destructive acceleration that accumulates catastrophe.

<!-- block: protection -->
There are cases where organizations braked internally. Intel abandoned the DRAM memory business when it was still profitable. IBM pivoted from hardware to services when the alternative was terminal decline. Microsoft reinvented its business model toward the cloud when its traditional markets were eroding. These cases are real and documented.

But they share a characteristic that is rarely mentioned when cited as counterexamples: they depended on specific individuals in specific positions at specific moments. Andy Grove at Intel making a decision that contradicted the company's historical identity. Lou Gerstner at IBM imposing a vision the organization actively resisted. Satya Nadella at Microsoft dismantling internal fiefdoms that had paralyzed previous transformations. When those individuals left, the organizations did not retain the structural capacity to brake. They retained the legend of having done it once.

The question is not whether any organization ever braked. Clearly some did. The question is whether that capability is reproducible without depending on individual heroism. If it requires an exceptional CEO willing to destroy short-term value to preserve long-term viability, it is not organizational architecture. It is biographical accident. And biographical accidents are not risk management strategy.

The power loop does not deny that exceptions exist. It establishes that exceptions cannot be designed, replicated, or institutionalized within the logic of the loop itself. Organizations that braked did not do so because their governance system worked. They did so because an individual with sufficient power forced the system to do something the system resisted.

There is no point within the loop where self-correction emerges naturally from the system. The same organizational structure that amplifies visible success is exactly the same structure that amplifies hidden error. There is no predefined internal threshold where the system automatically brakes its own acceleration. There is no organizational traffic light that changes from green to red when an invisible line is crossed. There is no institutional sensor that activates the alarm before impact.

Expecting the system to brake itself is equivalent to expecting gravity to stop working because it would be convenient. The loop will continue amplifying what it receives as long as it has available energy to do so. And in organizations with significant resources—abundant financial, consolidated political, deployed operational—the energy can last much longer than the real viability of the initiative it is feeding.

This is not a pessimistic observation about human nature or about organizations. It is the necessary foundation of any real and effective protection against systemic risk.

The only viable exit from the loop is a limit external to it. Something that does not respond to the loop's inertia nor is captured by its logic. Something that operates with criteria different from the amplification criteria that govern the system. Something that has real authority—not ceremonial, not consultative, but binding—to produce a complete halt before accumulated cost becomes irreversible.

Not an additional review committee that ends up being captured by the same political dynamic that captured the others. Not a new governance process that becomes a toothless periodic ritual without real power to change decisions already made. Not an extensive checklist that is mechanically completed each quarter without its result altering the course of action. A genuine limit with real and indisputable capacity to say no and make that no have operational consequences.

Boeing had extensive and documented internal controls. It had formal safety review processes established for decades. It had regulatory certifications that needed to be periodically renewed. It had internal and external audits. What it did not have was a mechanism genuinely external to the amplification loop with real authority to stop acceleration before it accumulated catastrophic consequences. All existing mechanisms had been, gradually and without malicious intent, integrated into the loop itself.

This is not organizational pessimism. It is real executive coverage.

Deeply understanding that strategic initiatives accelerate without visible internal control reduces your personal exposure to the board of directors. Not because you will avoid all errors—nobody can do that, and pretending otherwise would be dishonest—but because you stop blindly trusting that the system will self-regulate when necessary. That trust in systemic self-regulation is precisely the risk you are not seeing in your reports. It is the invisible and unexamined assumption that makes experienced, intelligent, and well-intentioned executives vulnerable.

Recognizing this structural dynamic allows you to brake or question an initiative without the questioning being read as lack of vision or personal commitment.

Your current strategic initiatives have amplification loops operating. All organizations with real capacity for action in the world have them. It is a structural characteristic, not a correctable defect. What determines the final outcome is whether there exist mechanisms genuinely external to those loops—not captured by them, not neutralized by their inertia—with real and binding capacity to produce a halt when necessary.

The next chapter examines the typical instinctive response when an executive perceives that something in the system is not working: increase internal control. More direct supervision, more frequent reports, more intermediate checkpoints, more layers of governance and approval. That response, far from solving the loop problem, accelerates it. Additional control without a genuine external limit is gasoline for the loop, not a brake.
